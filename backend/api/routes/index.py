"""
API —Ä–æ—É—Ç—ã –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–æ–≤
"""
import logging
import time
from fastapi import APIRouter, HTTPException, BackgroundTasks
from pydantic import BaseModel
from typing import Dict, Any

from ...indexers.simple_project_indexer import SimpleProjectIndexer
from ...indexers.python_indexer import PythonIndexer
from ...indexers.markdown_indexer import MarkdownIndexer
from ...rag.engine import RAGEngine

router = APIRouter()
logger = logging.getLogger(__name__)

class IndexResponse(BaseModel):
    status: str
    project: str
    message: str

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã
project_indexer = SimpleProjectIndexer()
python_indexer = PythonIndexer()
markdown_indexer = MarkdownIndexer()
rag_engine = None

async def get_rag_engine():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ RAG engine"""
    global rag_engine
    if rag_engine is None:
        rag_engine = RAGEngine()
        await rag_engine.initialize()
    return rag_engine

async def index_project_background(project_name: str):
    """–§–æ–Ω–æ–≤–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ (–ø–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)"""
    try:
        logger.info(f"=== –ù–∞—á–∞–ª–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {project_name} ===")
        start_time = time.time()
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ RAG engine
        rag = await get_rag_engine()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        # –í–ê–ñ–ù–û: –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º collection.get() - —ç—Ç–æ –º–µ–¥–ª–µ–Ω–Ω–æ –∏ –≤–∏—Å–Ω–µ—Ç
        # –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –ø—Ä–æ—Å—Ç–æ –ø—ã—Ç–∞–µ–º—Å—è –¥–æ–±–∞–≤–∏—Ç—å, ChromaDB —Å–∞–º –æ—Ç–±—Ä–æ—Å–∏—Ç –¥—É–±–ª–∏ –ø–æ ID
        indexed_files = set()  # –û—Å—Ç–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–º - –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞—Ä–∞–Ω–µ–µ
        logger.info(f"üìä –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –±–µ–∑ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ (–¥—É–±–ª–∏ –æ—Ç–±—Ä–æ—Å–∏—Ç ChromaDB)")
        
        stats = {
            'total_files': 0,
            'python_files': 0,
            'markdown_files': 0,
            'total_chunks': 0,
            'errors': 0
        }
        
        # –ü–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
        logger.info(f"üöÄ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ {project_name}")
        async for file_info in project_indexer.iter_project_files(project_name):
            try:
                file_path = file_info['file_path']
                file_type = file_info['file_type']
                relative_path = file_info['relative_path']
                
                stats['total_files'] += 1
                
                # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ñ–∞–π–ª–∞
                chunks = []
                if file_type == 'python':
                    chunks = await python_indexer.index_file(file_path)
                    stats['python_files'] += 1
                elif file_type == 'markdown':
                    chunks = await markdown_indexer.index_file(file_path)
                    stats['markdown_files'] += 1
                
                # –ó–∞–≥—Ä—É–∑–∫–∞ —á–∞–Ω–∫–æ–≤ –≤ ChromaDB
                for chunk in chunks:
                    try:
                        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                        doc_type = python_indexer._classify_doc_type(relative_path) if file_type == 'python' else 'documentation'
                        
                        await rag.store_document(
                            project=project_name,
                            content=chunk['content'],
                            metadata={
                                'file': relative_path,
                                'type': chunk['type'],
                                'doc_type': doc_type,
                                'start_line': chunk.get('start_line', 0),
                                'end_line': chunk.get('end_line', 0),
                                'lines': chunk.get('lines', f"{chunk.get('start_line', 0)}-{chunk.get('end_line', 0)}"),
                                'project': project_name,
                                'chunk_id': chunk.get('chunk_id', hash(chunk['content'][:100]))
                            }
                        )
                        stats['total_chunks'] += 1
                    except Exception as e:
                        stats['errors'] += 1
                        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —á–∞–Ω–∫–∞: {e}")
                
                # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                if stats['total_files'] % 50 == 0:
                    logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['total_files']} —Ñ–∞–π–ª–æ–≤, {stats['total_chunks']} —á–∞–Ω–∫–æ–≤, {stats['errors']} –æ—à–∏–±–æ–∫")
            
            except Exception as e:
                stats['errors'] += 1
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_info.get('relative_path', 'unknown')}: {e}")
        
        processing_time = time.time() - start_time
        
        logger.info(f"=== –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {processing_time:.2f}—Å ===")
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: —Ñ–∞–π–ª–æ–≤={stats['total_files']}, —á–∞–Ω–∫–æ–≤={stats['total_chunks']}, –æ—à–∏–±–æ–∫={stats['errors']}")
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}", exc_info=True)

@router.post("/index/{project_name}", response_model=IndexResponse)
async def index_project(project_name: str, background_tasks: BackgroundTasks):
    """
    –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –ø—Ä–æ–µ–∫—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        project_indexer.load_config()
        project_names = [p['name'] for p in project_indexer.projects]
        
        if project_name not in project_names:
            raise HTTPException(
                status_code=404,
                detail=f"–ü—Ä–æ–µ–∫—Ç {project_name} –Ω–µ –Ω–∞–π–¥–µ–Ω. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {project_names}"
            )
        
        # –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏
        background_tasks.add_task(index_project_background, project_name)
        
        return IndexResponse(
            status="started",
            project=project_name,
            message=f"–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ {project_name} –∑–∞–ø—É—â–µ–Ω–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ. –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –ª–æ–≥–∏ Docker."
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/index/status/{project_name}")
async def get_index_status(project_name: str):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
    """
    try:
        rag = await get_rag_engine()
        
        # –ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        count = rag.collection.count()
        
        return {
            "project": project_name,
            "total_documents": count,
            "status": "indexed" if count > 0 else "empty",
            "message": f"–í –±–∞–∑–µ {count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"
        }
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))
