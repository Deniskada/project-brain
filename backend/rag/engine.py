"""
RAG Engine - –æ—Å–Ω–æ–≤–Ω–æ–π –¥–≤–∏–∂–æ–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤
"""
import logging
from typing import List, Dict, Any, Optional
import asyncio
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings

logger = logging.getLogger(__name__)

class RAGEngine:
    def __init__(self):
        self.chroma_client = None
        self.embedding_model = None
        self.collection = None
        
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG engine"""
        try:
            import os
            
            chroma_host = os.getenv("CHROMA_HOST", "chromadb").replace("http://", "").split(":")[0]
            chroma_port = int(os.getenv("CHROMA_PORT", "8000"))
            
            logger.info(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ ChromaDB: {chroma_host}:{chroma_port}")
            
            # ChromaDB 0.5.x - –Ω–æ–≤—ã–π API
            self.chroma_client = chromadb.HttpClient(
                host=chroma_host,
                port=chroma_port
            )
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
            
            # –ù–ï —Å–æ–∑–¥–∞—ë–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –∑–¥–µ—Å—å - –±—É–¥–µ–º —Å–æ–∑–¥–∞–≤–∞—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ –æ—Ç–¥–µ–ª—å–Ω–æ
            self.collection = None  # –ë—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ —á–µ—Ä–µ–∑ get_collection()
            
            logger.info(f"‚úÖ RAG Engine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ (–±–µ–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏)")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ RAG Engine: {e}", exc_info=True)
            raise
    
    def get_collection(self, project: str):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞"""
        collection_name = f"kb_{project.replace('-', '_')}"  # kb_staffprobot, kb_project_brain
        
        try:
            collection = self.chroma_client.get_or_create_collection(
                name=collection_name,
                metadata={"description": f"Knowledge base for {project}"}
            )
            logger.info(f"üìö –ò—Å–ø–æ–ª—å–∑—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é: {collection_name}")
            return collection
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {collection_name}: {e}")
            raise
    
    def _detect_query_intent(self, query: str) -> Dict[str, Any]:
        """
        –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        """
        query_lower = query.lower()
        intent = {
            'type': 'general',
            'preferred_doc_types': [],
            'keywords': []
        }
        
        # –û–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –æ –ø—Ä–æ–µ–∫—Ç–µ - README, –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
        overview_keywords = ['—Ä–∞—Å—Å–∫–∞–∂–∏', '—á—Ç–æ —ç—Ç–æ', '–æ —Å–∏—Å—Ç–µ–º–µ', '–æ –ø—Ä–æ–µ–∫—Ç–µ', '—Ü–µ–ª–∏', '–∑–∞–¥–∞—á–∏',
                            '–Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ', '–¥–ª—è —á–µ–≥–æ', '–∑–∞—á–µ–º', '–æ–ø–∏—Å–∞–Ω–∏–µ', 'overview']
        if any(kw in query_lower for kw in overview_keywords):
            intent['type'] = 'overview'
            intent['preferred_doc_types'] = ['documentation']  # README, –æ–ø–∏—Å–∞–Ω–∏—è
        
        # –í–æ–ø—Ä–æ—Å—ã "–∫–∞–∫ —Å–¥–µ–ª–∞—Ç—å X" - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç —É–∑–Ω–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å
        how_keywords = ['–∫–∞–∫', 'how', '—á—Ç–æ –Ω—É–∂–Ω–æ', '–∫–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º', '—Å–ø–æ—Å–æ–±', '–º–µ—Ç–æ–¥', 
                        '–ø—Ä–æ—Ü–µ—Å—Å', '–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è', '—à–∞–≥–∏']
        if any(kw in query_lower for kw in how_keywords):
            intent['type'] = 'how_to'
            intent['preferred_doc_types'] = ['route', 'handler', 'service']
            
            # –ï—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –ø—Ä–æ —Å–æ–∑–¥–∞–Ω–∏–µ/–∏–∑–º–µ–Ω–µ–Ω–∏–µ - —Ç–æ—á–Ω–æ —Ä–æ—É—Ç—ã
            action_keywords = ['—Å–æ–∑–¥–∞—Ç—å', '–¥–æ–±–∞–≤–∏—Ç—å', '–∏–∑–º–µ–Ω–∏—Ç—å', '—É–¥–∞–ª–∏—Ç—å', '–æ–±–Ω–æ–≤–∏—Ç—å',
                              'create', 'add', 'update', 'delete', 'modify']
            if any(kw in query_lower for kw in action_keywords):
                intent['preferred_doc_types'] = ['route', 'handler', 'api']
        
        # –í–æ–ø—Ä–æ—Å—ã –ø—Ä–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö - –º–æ–¥–µ–ª–∏ –ë–î
        structure_keywords = ['–ø–æ–ª—è', '–º–æ–¥–µ–ª—å', '—Ç–∞–±–ª–∏—Ü–∞', 'schema', 'fields', '—Å—Ç—Ä—É–∫—Ç—É—Ä–∞',
                             '–∞—Ç—Ä–∏–±—É—Ç—ã', '–∫–æ–ª–æ–Ω–∫–∏', '—Å—Ç–æ–ª–±—Ü—ã']
        if any(kw in query_lower for kw in structure_keywords):
            intent['type'] = 'structure'
            intent['preferred_doc_types'] = ['model', 'schema']
        
        # –í–æ–ø—Ä–æ—Å—ã –ø—Ä–æ API
        api_keywords = ['api', 'endpoint', '—Ä–æ—É—Ç', 'route', '–∑–∞–ø—Ä–æ—Å', 'request']
        if any(kw in query_lower for kw in api_keywords):
            intent['type'] = 'api'
            intent['preferred_doc_types'] = ['route', 'api']
        
        # –í–æ–ø—Ä–æ—Å—ã –ø—Ä–æ –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É
        logic_keywords = ['–ª–æ–≥–∏–∫–∞', '–æ–±—Ä–∞–±–æ—Ç–∫–∞', '–∞–ª–≥–æ—Ä–∏—Ç–º', '–±–∏–∑–Ω–µ—Å', '–ø—Ä–∞–≤–∏–ª–∞']
        if any(kw in query_lower for kw in logic_keywords):
            intent['type'] = 'logic'
            intent['preferred_doc_types'] = ['service', 'handler']
        
        return intent
    
    def _rerank_results(
        self, 
        results: List[Dict[str, Any]], 
        intent: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        –ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        preferred_types = intent.get('preferred_doc_types', [])
        
        if not preferred_types:
            return results
        
        # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –±–æ–Ω—É—Å—ã —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        for result in results:
            doc_type = result.get('doc_type', 'other')
            
            # –°–∏–ª—å–Ω—ã–π –±—É—Å—Ç –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ç–∏–ø–∞
            if doc_type in preferred_types:
                boost_index = preferred_types.index(doc_type)
                # –ü–µ—Ä–≤—ã–π –≤ —Å–ø–∏—Å–∫–µ –ø–æ–ª—É—á–∞–µ—Ç –±–æ–ª—å—à–∏–π –±—É—Å—Ç
                boost = 0.3 - (boost_index * 0.1)
                result['score'] = min(1.0, result['score'] + boost)
            
            # –ù–µ–±–æ–ª—å—à–æ–π —à—Ç—Ä–∞—Ñ –¥–ª—è –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ç–∏–ø–æ–≤
            elif len(preferred_types) > 0 and doc_type == 'model' and 'route' in preferred_types:
                result['score'] *= 0.7
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–≤–æ–º—É score
        return sorted(results, key=lambda x: x['score'], reverse=True)
    
    async def retrieve_context(
        self, 
        query: str, 
        project: str = "staffprobot",
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ —Å —É–º–Ω–æ–π –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–µ–π
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
            collection = self.get_collection(project)
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            intent = self._detect_query_intent(query)
            logger.info(f"Query intent: {intent['type']}, preferred types: {intent['preferred_doc_types']}")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = self.embedding_model.encode(query).tolist()
            
            # –î–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è "how_to" –∏ "overview" –∑–∞–ø—Ä–æ—Å–æ–≤
            context_docs = []
            
            if intent['type'] in ['how_to', 'overview'] and intent['preferred_doc_types']:
                # –≠—Ç–∞–ø 1: –ò—â–µ–º –≤ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç–∏–ø–∞—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
                try:
                    where_clause = {
                        "$or": [{"doc_type": dt} for dt in intent['preferred_doc_types']]
                    }
                    
                    results_priority = collection.query(
                        query_embeddings=[query_embedding],
                        n_results=top_k,
                        where=where_clause
                    )
                    
                    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    if results_priority['documents'] and results_priority['documents'][0]:
                        for i, doc in enumerate(results_priority['documents'][0]):
                            context_docs.append({
                                "content": doc,
                                "file": results_priority['metadatas'][0][i].get('file', ''),
                                "lines": results_priority['metadatas'][0][i].get('lines', ''),
                                "type": results_priority['metadatas'][0][i].get('type', ''),
                                "doc_type": results_priority['metadatas'][0][i].get('doc_type', 'other'),
                                "score": 1 - results_priority['distances'][0][i] if results_priority['distances'] else 0.0
                            })
                    
                    logger.info(f"Found {len(context_docs)} results in priority types")
                
                except Exception as e:
                    logger.warning(f"Priority search failed: {e}, falling back to general search")
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ - –æ–±—â–∏–π –ø–æ–∏—Å–∫
            if len(context_docs) < top_k:
                remaining = top_k - len(context_docs)
                
                # –û–±—â–∏–π –ø–æ–∏—Å–∫ –ë–ï–ó where (–∫–æ–ª–ª–µ–∫—Ü–∏—è —É–∂–µ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞)
                results = collection.query(
                    query_embeddings=[query_embedding],
                    n_results=top_k * 2  # –ë–µ—Ä—ë–º –±–æ–ª—å—à–µ –¥–ª—è –ø–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
                )
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                if results['documents'] and results['documents'][0]:
                    for i, doc in enumerate(results['documents'][0]):
                        doc_data = {
                            "content": doc,
                            "file": results['metadatas'][0][i].get('file', ''),
                            "lines": results['metadatas'][0][i].get('lines', ''),
                            "type": results['metadatas'][0][i].get('type', ''),
                            "doc_type": results['metadatas'][0][i].get('doc_type', 'other'),
                            "score": 1 - results['distances'][0][i] if results['distances'] else 0.0
                        }
                        
                        # –ò–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–µ–π
                        if not any(d['file'] == doc_data['file'] and d['lines'] == doc_data['lines'] 
                                  for d in context_docs):
                            context_docs.append(doc_data)
            
            # –ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
            context_docs = self._rerank_results(context_docs, intent)
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º top_k –ª—É—á—à–∏—Ö
            final_results = context_docs[:top_k]
            logger.info(f"Returning {len(final_results)} results after reranking")
            
            return final_results
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
            return []
    
    async def get_relevant_rules(
        self,
        file_path: str = "",
        role: str = "",
        module: str = "",
        project: str = "staffprobot"
    ) -> List[str]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
            collection = self.get_collection(project)
            
            # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø—Ä–∞–≤–∏–ª
            query_parts = []
            
            if role:
                query_parts.append(f"—Ä–æ–ª—å {role}")
            if file_path:
                if "routes" in file_path:
                    query_parts.append("—Ä–æ—É—Ç—ã")
                if "owner" in file_path:
                    query_parts.append("–≤–ª–∞–¥–µ–ª–µ—Ü")
                if "manager" in file_path:
                    query_parts.append("—É–ø—Ä–∞–≤–ª—è—é—â–∏–π")
                if "employee" in file_path:
                    query_parts.append("—Å–æ—Ç—Ä—É–¥–Ω–∏–∫")
            if module:
                query_parts.append(module)
            
            if not query_parts:
                return []
            
            query = " ".join(query_parts)
            
            # –ü–æ–∏—Å–∫ –ø—Ä–∞–≤–∏–ª –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
            results = collection.query(
                query_texts=[query],
                n_results=10,
                where={"type": "rule"}
            )
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª
            rules = []
            if results['documents'] and results['documents'][0]:
                for doc in results['documents'][0]:
                    rules.append(doc)
            
            return rules[:5]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∞–≤–∏–ª
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–∞–≤–∏–ª: {e}")
            return []
    
    async def store_document(
        self,
        project: str,
        content: str,
        metadata: Dict[str, Any]
    ):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
            collection = self.get_collection(project)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
            embedding = self.embedding_model.encode(content).tolist()
            
            # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID: –∏—Å–ø–æ–ª—å–∑—É–µ–º chunk_id –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º —Ö–µ—à
            chunk_id = metadata.get('chunk_id', hash(f"{metadata.get('file', '')}_{metadata.get('start_line', 0)}_{content[:50]}"))
            doc_id = f"{project}_{chunk_id}"
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ ChromaDB (—Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥—É–±–ª–µ–π)
            try:
                collection.add(
                    embeddings=[embedding],
                    documents=[content],
                    metadatas=[metadata],
                    ids=[doc_id]
                )
            except Exception as e:
                # –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                if "already exists" in str(e) or "duplicate" in str(e).lower():
                    pass  # –¢–∏—Ö–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏
                else:
                    raise  # –î—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏ –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            # –ù–µ –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É - –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
    
    async def query(
        self,
        query: str,
        project: str = "staffprobot",
        top_k: int = 5
    ) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω—ã–π RAG –∑–∞–ø—Ä–æ—Å: –ø–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        """
        try:
            # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            context_docs = await self.retrieve_context(
                query=query,
                project=project,
                top_k=top_k
            )
            
            # –ò–º–ø–æ—Ä—Ç Ollama –∫–ª–∏–µ–Ω—Ç–∞
            from ..llm.ollama_client import OllamaClient
            ollama = OllamaClient()
            await ollama.initialize()
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º (–ø–µ—Ä–µ–¥–∞—ë–º –∏–º—è –ø—Ä–æ–µ–∫—Ç–∞!)
            answer = await ollama.generate_response(
                query=query,
                context=context_docs,
                max_tokens=1000,
                project_name=project
            )
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            sources = []
            for doc in context_docs:
                sources.append({
                    "file": doc.get("file", ""),
                    "lines": doc.get("lines", ""),
                    "content": doc.get("content", "")[:200] + "...",
                    "score": doc.get("score", 0.0)
                })
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª
            relevant_rules = await self.get_relevant_rules(
                file_path="",
                role="",
                project=project
            )
            
            return {
                "answer": answer,
                "sources": sources,
                "relevant_rules": relevant_rules
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ RAG –∑–∞–ø—Ä–æ—Å–∞: {e}", exc_info=True)
            return {
                "answer": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}",
                "sources": [],
                "relevant_rules": []
            }
