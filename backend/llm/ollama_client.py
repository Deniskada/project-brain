"""
Ollama –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM
"""
import logging
import httpx
from typing import List, Dict, Any, Optional
import json
import os

logger = logging.getLogger(__name__)

class OllamaClient:
    def __init__(self, base_url: str = None):
        # –ß–∏—Ç–∞–µ–º URL –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.base_url = base_url or os.getenv("OLLAMA_HOST", "http://localhost:11434")
        self.model = "qwen2.5:14b-instruct"  # Qwen 2.5 14B - –ª—É—á—à–∞—è –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ! (8.9GB)
        self.fallback_model = "codellama:13b-instruct"  # Fallback –º–æ–¥–µ–ª—å (7.4GB)
        logger.info(f"OllamaClient –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å base_url: {self.base_url}")
        
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É)"""
        logger.info(f"Ollama –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å URL: {self.base_url}")
        logger.info(f"–ú–æ–¥–µ–ª—å: {self.model}, Fallback: {self.fallback_model}")
    
    async def generate_response(
        self,
        query: str,
        context: List[Dict[str, Any]],
        max_tokens: int = 1000
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        """
        try:
            logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –º–æ–¥–µ–ª—å—é: {self.model}")
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
            prompt = self._build_prompt(query, context)
            logger.info(f"–ü—Ä–æ–º–ø—Ç: {prompt[:100]}...")
            
            # –ó–∞–ø—Ä–æ—Å –∫ Ollama —á–µ—Ä–µ–∑ requests
            import requests
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "num_predict": max_tokens,
                        "temperature": 0.7,
                        "top_p": 0.9
                    }
                },
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get("response", "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞")
            else:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Ollama: {response.status_code}")
                return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}"
    
    def _build_prompt(self, query: str, context: List[Dict[str, Any]]) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è LLM —Å —É—á—ë—Ç–æ–º —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
        doc_types = {}
        for doc in context:
            doc_type = doc.get('doc_type', 'other')
            doc_types.setdefault(doc_type, []).append(doc)
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        system_prompt = """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ–µ–∫—Ç—É StaffProBot, —Å–∏—Å—Ç–µ–º–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª–æ–º. 
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –∫–æ–¥–µ, –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞.

–ü—Ä–∞–≤–∏–ª–∞:
1. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –∫—Ä–∞—Ç–∫–æ –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ
2. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —É–∫–∞–∑—ã–≤–∞–π —Ñ–∞–π–ª—ã –∏ —Å—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
3. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —Ä–æ—É—Ç—ã (routes) –∏–ª–∏ —Ö–µ–Ω–¥–ª–µ—Ä—ã (handlers) - –∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö –ü–ï–†–í–´–ú–ò –¥–ª—è –æ—Ç–≤–µ—Ç–∞
4. –î–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ "–∫–∞–∫ —Å–¥–µ–ª–∞—Ç—å" - –ø–æ–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∫–æ–¥ –∏ —à–∞–≥–∏
5. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ - —Å–∫–∞–∂–∏ —á–µ—Å—Ç–Ω–æ

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∫–æ–¥–æ–≤–æ–π –±–∞–∑—ã (—É–ø–æ—Ä—è–¥–æ—á–µ–Ω –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏):"""

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–µ–π
        context_text = ""
        context_order = ['route', 'handler', 'api', 'service', 'form', 'model', 'schema', 'other']
        
        context_num = 1
        for doc_type in context_order:
            if doc_type in doc_types:
                for doc in doc_types[doc_type]:
                    # –ú–µ—Ç–∫–∞ —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è
                    type_label = {
                        'route': 'üîó –†–û–£–¢ (API endpoint)',
                        'handler': '‚ö° –•–ï–ù–î–õ–ï–† (–æ–±—Ä–∞–±–æ—Ç—á–∏–∫)',
                        'api': 'üì° API',
                        'service': 'üîß –°–ï–†–í–ò–° (–±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞)',
                        'form': 'üìù –§–û–†–ú–ê',
                        'model': 'üóÑÔ∏è –ú–û–î–ï–õ–¨ –ë–î',
                        'schema': 'üìã –°–•–ï–ú–ê',
                        'other': 'üìÑ –î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–Ø'
                    }.get(doc_type, 'üìÑ')
                    
                    file_info = f"{type_label}\n–§–∞–π–ª: {doc.get('file', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}"
                    if doc.get('lines'):
                        file_info += f"\n–°—Ç—Ä–æ–∫–∏: {doc['lines']}"
                    
                    # –û–±—Ä–µ–∑–∞–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
                    content = doc.get('content', '')
                    if len(content) > 800:
                        content = content[:800] + "\n... (–∫–æ–Ω—Ç–µ–Ω—Ç –æ–±—Ä–µ–∑–∞–Ω)"
                    
                    context_text += f"\n\n--- –ö–æ–Ω—Ç–µ–∫—Å—Ç {context_num} ---\n{file_info}\n\n{content}"
                    context_num += 1
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        full_prompt = f"""{system_prompt}

{context_text}

–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {query}

–¢–≤–æ–π –æ—Ç–≤–µ—Ç (–Ω–∞—á–Ω–∏ —Å—Ä–∞–∑—É —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏):"""

        return full_prompt
    
    async def test_connection(self) -> bool:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{self.base_url}/api/tags")
                return response.status_code == 200
        except:
            return False
