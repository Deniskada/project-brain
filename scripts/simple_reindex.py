#!/usr/bin/env python3
"""
ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ ÑÐºÑ€Ð¸Ð¿Ñ‚ Ð¿ÐµÑ€ÐµÐ¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸ - Ð·Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ð°
"""
import asyncio
import sys
sys.path.insert(0, '/app')

from backend.indexers.simple_project_indexer import SimpleProjectIndexer
from backend.indexers.python_indexer import PythonIndexer
from backend.indexers.markdown_indexer import MarkdownIndexer
from backend.rag.engine import RAGEngine
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def reindex_project(project_name: str):
    """ÐŸÐµÑ€ÐµÐ¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ñ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°"""
    logger.info(f"ðŸš€ ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð¿ÐµÑ€ÐµÐ¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸: {project_name}")
    
    # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
    project_indexer = SimpleProjectIndexer()
    project_indexer.load_config()
    python_indexer = PythonIndexer()
    markdown_indexer = MarkdownIndexer()
    rag_engine = RAGEngine()
    await rag_engine.initialize()
    
    stats = {
        'total_files': 0,
        'total_chunks': 0,
        'errors': 0
    }
    
    # Ð˜Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ñ
    async for file_info in project_indexer.iter_project_files(project_name):
        try:
            file_path = file_info['file_path']
            file_type = file_info['file_type']
            relative_path = file_info['relative_path']
            
            stats['total_files'] += 1
            
            # Ð˜Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð°
            chunks = []
            if file_type == 'python':
                chunks = await python_indexer.index_file(file_path)
            elif file_type == 'markdown':
                chunks = await markdown_indexer.index_file(file_path)
            
            # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ‡Ð°Ð½ÐºÐ¾Ð²
            for chunk in chunks:
                doc_type = python_indexer._classify_doc_type(relative_path) if file_type == 'python' else 'documentation'
                
                await rag_engine.store_document(
                    project=project_name,
                    content=chunk['content'],
                    metadata={
                        'file': relative_path,
                        'type': chunk['type'],
                        'doc_type': doc_type,
                        'start_line': chunk.get('start_line', 0),
                        'end_line': chunk.get('end_line', 0),
                        'lines': chunk.get('lines', '0-0'),
                        'project': project_name,
                        'chunk_id': chunk.get('chunk_id', hash(chunk['content'][:100]))
                    }
                )
                stats['total_chunks'] += 1
            
            # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑ
            if stats['total_files'] % 10 == 0:
                logger.info(f"ðŸ“Š ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð¾ Ñ„Ð°Ð¹Ð»Ð¾Ð²: {stats['total_files']}, Ñ‡Ð°Ð½ÐºÐ¾Ð²: {stats['total_chunks']}")
        
        except Exception as e:
            stats['errors'] += 1
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ {relative_path}: {e}")
    
    logger.info(f"âœ… Ð˜Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°: {stats}")
    return stats

if __name__ == "__main__":
    project = sys.argv[1] if len(sys.argv) > 1 else "staffprobot"
    asyncio.run(reindex_project(project))

