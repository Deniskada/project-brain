#!/usr/bin/env python3
"""
–ó–∞–≥—Ä—É–∑—á–∏–∫ –≤—Å–µ—Ö QA –ø–∞—Ä –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ QA –ø–∞—Ä –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤ ChromaDB
"""
import sys
import json
import logging
from pathlib import Path
from typing import List, Dict, Any

sys.path.insert(0, '/app')

from backend.rag.engine import RAGEngine

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

class QALoader:
    def __init__(self):
        self.rag_engine = RAGEngine()
        self.qa_pairs = []
        
    def load_all_qa_sources(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ QA –ø–∞—Ä –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        logger.info("üìö –ó–∞–≥—Ä—É–∑–∫–∞ QA –ø–∞—Ä –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")
        
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ QA –ø–∞—Ä—ã
        existing_pairs = self._load_existing_qa_pairs()
        self.qa_pairs.extend(existing_pairs)
        logger.info(f"‚úÖ –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ QA –ø–∞—Ä—ã: {len(existing_pairs)}")
        
        # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º QA –ø–∞—Ä—ã –∏–∑ –≥—Ä–∞—Ñ–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        graph_pairs = self._load_graph_qa_pairs()
        self.qa_pairs.extend(graph_pairs)
        logger.info(f"‚úÖ QA –ø–∞—Ä—ã –∏–∑ –≥—Ä–∞—Ñ–∞: {len(graph_pairs)}")
        
        # 3. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞—Å—Å–æ–≤—ã–µ QA –ø–∞—Ä—ã
        massive_pairs = self._load_massive_qa_pairs()
        self.qa_pairs.extend(massive_pairs)
        logger.info(f"‚úÖ –ú–∞—Å—Å–æ–≤—ã–µ QA –ø–∞—Ä—ã: {len(massive_pairs)}")
        
        # 4. –ó–∞–≥—Ä—É–∂–∞–µ–º –¶–ï–õ–ï–í–´–ï QA –ø–∞—Ä—ã (–ù–û–í–û–ï!)
        targeted_pairs = self._load_targeted_qa_pairs()
        self.qa_pairs.extend(targeted_pairs)
        logger.info(f"‚úÖ –¶–µ–ª–µ–≤—ã–µ QA –ø–∞—Ä—ã: {len(targeted_pairs)}")
        
        # 5. –ó–∞–≥—Ä—É–∂–∞–µ–º –°–£–ü–ï–†-–î–ï–¢–ê–õ–¨–ù–´–ï QA –ø–∞—Ä—ã (–ù–û–í–û–ï!)
        super_pairs = self._load_super_detailed_qa_pairs()
        self.qa_pairs.extend(super_pairs)
        logger.info(f"‚úÖ –°—É–ø–µ—Ä-–¥–µ—Ç–∞–ª—å–Ω—ã–µ QA –ø–∞—Ä—ã: {len(super_pairs)}")
        
        # 6. –ó–∞–≥—Ä—É–∂–∞–µ–º QA –ø–∞—Ä—ã –∏–∑ —Ç–µ—Å—Ç–æ–≤
        test_pairs = self._load_test_qa_pairs()
        self.qa_pairs.extend(test_pairs)
        logger.info(f"‚úÖ –¢–µ—Å—Ç–æ–≤—ã–µ QA –ø–∞—Ä—ã: {len(test_pairs)}")
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_pairs = self._remove_duplicates()
        logger.info(f"üìä –í–°–ï–ì–û —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö QA –ø–∞—Ä: {len(unique_pairs)}")
        
        return unique_pairs
    
    def _load_existing_qa_pairs(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö QA –ø–∞—Ä"""
        try:
            with open("/tmp/generated_qa_pairs.json", 'r', encoding='utf-8') as f:
                pairs = json.load(f)
            logger.info(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ generated_qa_pairs.json: {len(pairs)}")
            return pairs
        except FileNotFoundError:
            logger.warning("‚ö†Ô∏è –§–∞–π–ª generated_qa_pairs.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return []
    
    def _load_graph_qa_pairs(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ QA –ø–∞—Ä –∏–∑ –≥—Ä–∞—Ñ–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
        try:
            with open("/tmp/graph_qa_pairs.json", 'r', encoding='utf-8') as f:
                pairs = json.load(f)
            logger.info(f"üîó –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ graph_qa_pairs.json: {len(pairs)}")
            return pairs
        except FileNotFoundError:
            logger.warning("‚ö†Ô∏è –§–∞–π–ª graph_qa_pairs.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return []
    
    def _load_massive_qa_pairs(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–∞—Å—Å–æ–≤—ã—Ö QA –ø–∞—Ä"""
        try:
            with open("/tmp/massive_qa_pairs.json", 'r', encoding='utf-8') as f:
                pairs = json.load(f)
            logger.info(f"üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ massive_qa_pairs.json: {len(pairs)}")
            return pairs
        except FileNotFoundError:
            logger.warning("‚ö†Ô∏è –§–∞–π–ª massive_qa_pairs.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return []
    
    def _load_targeted_qa_pairs(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ü–µ–ª–µ–≤—ã—Ö QA –ø–∞—Ä"""
        try:
            with open("/tmp/targeted_qa_pairs.json", 'r', encoding='utf-8') as f:
                pairs = json.load(f)
            logger.info(f"üéØ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ targeted_qa_pairs.json: {len(pairs)}")
            return pairs
        except FileNotFoundError:
            logger.warning("‚ö†Ô∏è –§–∞–π–ª targeted_qa_pairs.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return []
    
    def _load_super_detailed_qa_pairs(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—É–ø–µ—Ä-–¥–µ—Ç–∞–ª—å–Ω—ã—Ö QA –ø–∞—Ä"""
        try:
            with open("/tmp/super_detailed_qa_pairs.json", 'r', encoding='utf-8') as f:
                pairs = json.load(f)
            logger.info(f"üöÄ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ super_detailed_qa_pairs.json: {len(pairs)}")
            return pairs
        except FileNotFoundError:
            logger.warning("‚ö†Ô∏è –§–∞–π–ª super_detailed_qa_pairs.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return []
    
    def _load_test_qa_pairs(self) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö QA –ø–∞—Ä"""
        try:
            with open("/app/tests/test_staffprobot_queries.json", 'r', encoding='utf-8') as f:
                test_data = json.load(f)
            
            pairs = []
            for item in test_data:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ item - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
                if isinstance(item, dict) and "question" in item:
                    pairs.append({
                        "question": item["question"],
                        "answer": item.get("expected_answer", "–û—Ç–≤–µ—Ç –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω"),
                        "metadata": {
                            "category": item.get("category", "test"),
                            "difficulty": item.get("difficulty", "medium"),
                            "topic": item.get("topic", "general")
                        }
                    })
            
            logger.info(f"üß™ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ test_staffprobot_queries.json: {len(pairs)}")
            return pairs
        except FileNotFoundError:
            logger.warning("‚ö†Ô∏è –§–∞–π–ª test_staffprobot_queries.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return []
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–µ—Å—Ç–æ–≤—ã—Ö QA –ø–∞—Ä: {e}")
            return []
    
    def _remove_duplicates(self) -> List[Dict[str, Any]]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ –≤–æ–ø—Ä–æ—Å—É"""
        seen_questions = set()
        unique_pairs = []
        
        for pair in self.qa_pairs:
            question = pair["question"].lower().strip()
            if question not in seen_questions:
                seen_questions.add(question)
                unique_pairs.append(pair)
        
        logger.info(f"üîÑ –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(self.qa_pairs) - len(unique_pairs)}")
        return unique_pairs
    
    async def store_qa_pairs(self, pairs: List[Dict[str, Any]]) -> int:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ QA –ø–∞—Ä –≤ ChromaDB"""
        logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {len(pairs)} QA –ø–∞—Ä –≤ ChromaDB...")
        
        stored_count = 0
        for i, pair in enumerate(pairs):
            try:
                # –°–æ–∑–¥–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è ChromaDB
                doc_id = f"qa_pair_{i}_{hash(pair['question'])}"
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞
                content = f"–í–æ–ø—Ä–æ—Å: {pair['question']}\n\n–û—Ç–≤–µ—Ç: {pair['answer']}"
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–ë–ï–ó answer - –æ–Ω —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π!)
                metadata = {
                    "type": "qa_pair",
                    "question": pair["question"][:500],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
                    "source": "qa_training",
                    "chunk_id": f"qa_{i}_{hash(pair['question'])}"  # –£–ù–ò–ö–ê–õ–¨–ù–´–ô ID!
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–¢–û–õ–¨–ö–û –ø—Ä–æ—Å—Ç—ã–µ —Ç–∏–ø—ã!)
                if "metadata" in pair:
                    for key, value in pair["metadata"].items():
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ str, int, float, bool
                        if isinstance(value, (str, int, float, bool)):
                            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Å—Ç—Ä–æ–∫
                            if isinstance(value, str):
                                metadata[key] = value[:200]
                            else:
                                metadata[key] = value
                
                # chunk_id –æ—Å—Ç–∞–µ—Ç—Å—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–º
                metadata["chunk_id"] = f"qa_{i}_{hash(pair['question'])}"
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ ChromaDB (ASYNC!)
                await self.rag_engine.store_document(
                    project="staffprobot",
                    content=content,
                    metadata=metadata
                )
                
                stored_count += 1
                
                if stored_count % 100 == 0:
                    logger.info(f"  üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {stored_count}/{len(pairs)} QA –ø–∞—Ä")
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è QA –ø–∞—Ä—ã {i}: {e}")
        
        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {stored_count} QA –ø–∞—Ä")
        return stored_count
    
    def generate_summary_report(self, pairs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø–æ QA –ø–∞—Ä–∞–º"""
        categories = {}
        difficulties = {}
        sources = {}
        
        for pair in pairs:
            metadata = pair.get("metadata", {})
            
            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏
            category = metadata.get("category", "unknown")
            categories[category] = categories.get(category, 0) + 1
            
            # –°–ª–æ–∂–Ω–æ—Å—Ç—å
            difficulty = metadata.get("difficulty", "unknown")
            difficulties[difficulty] = difficulties.get(difficulty, 0) + 1
            
            # –ò—Å—Ç–æ—á–Ω–∏–∫–∏
            source = metadata.get("source", "unknown")
            sources[source] = sources.get(source, 0) + 1
        
        return {
            "total_pairs": len(pairs),
            "categories": categories,
            "difficulties": difficulties,
            "sources": sources
        }

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ QA –ø–∞—Ä"""
    logger.info("üöÄ –ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –≤—Å–µ—Ö QA –ø–∞—Ä –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π...")
    
    loader = QALoader()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ QA –ø–∞—Ä—ã
    all_pairs = loader.load_all_qa_sources()
    
    if not all_pairs:
        logger.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ QA –ø–∞—Ä –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏!")
        return
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    report = loader.generate_summary_report(all_pairs)
    
    logger.info("\nüìä –û–¢–ß–ï–¢ –ü–û QA –ü–ê–†–ê–ú:")
    logger.info(f"–í—Å–µ–≥–æ –ø–∞—Ä: {report['total_pairs']}")
    
    logger.info("\nüìÇ –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
    for category, count in sorted(report['categories'].items()):
        logger.info(f"  ‚Ä¢ {category}: {count}")
    
    logger.info("\nüéØ –ü–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏:")
    for difficulty, count in sorted(report['difficulties'].items()):
        logger.info(f"  ‚Ä¢ {difficulty}: {count}")
    
    logger.info("\nüìö –ü–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:")
    for source, count in sorted(report['sources'].items()):
        logger.info(f"  ‚Ä¢ {source}: {count}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º QA –ø–∞—Ä—ã –≤ ChromaDB (ASYNC!)
    stored_count = await loader.store_qa_pairs(all_pairs)
    
    logger.info(f"\nüéâ –ó–ê–ì–†–£–ó–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
    logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {stored_count} QA –ø–∞—Ä –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π")
    logger.info(f"üìà –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —Ç–µ–ø–µ—Ä—å —Å–æ–¥–µ—Ä–∂–∏—Ç {stored_count} –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
