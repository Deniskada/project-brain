#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä —Å –±–æ–ª—å—à–∏–º–∏ —á–∞–Ω–∫–∞–º–∏ –∏ –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
–¶–µ–ª—å: 85-90% –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤
"""
import ast
import os
import sys
import re
from pathlib import Path
from typing import List, Dict, Any, Optional
import logging

sys.path.insert(0, '/app')

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

class EnhancedPythonIndexer:
    def __init__(self):
        self.min_chunk_size = 500  # –ú–∏–Ω–∏–º—É–º 500 —Ç–æ–∫–µ–Ω–æ–≤
        self.overlap_size = 100    # –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ 100 —Ç–æ–∫–µ–Ω–æ–≤
        
    async def index_file(self, file_path: str) -> List[Dict[str, Any]]:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ñ–∞–π–ª–∞ —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            chunks = []
            
            # 1. –ü–æ–ª–Ω—ã–π —Ñ–∞–π–ª –∫–∞–∫ –æ–¥–∏–Ω –±–æ–ª—å—à–æ–π —á–∞–Ω–∫ (–¥–ª—è –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤)
            full_chunk = await self._create_full_file_chunk(content, file_path)
            if full_chunk:
                chunks.append(full_chunk)
            
            # 2. –ö–ª–∞—Å—Å—ã —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    class_chunk = await self._create_enhanced_class_chunk(node, content, file_path)
                    if class_chunk:
                        chunks.append(class_chunk)
            
            # 3. –§—É–Ω–∫—Ü–∏–∏ —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    func_chunk = await self._create_enhanced_function_chunk(node, content, file_path)
                    if func_chunk:
                        chunks.append(func_chunk)
            
            # 4. –ò–º–ø–æ—Ä—Ç—ã –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
            imports_chunk = await self._create_imports_chunk(tree, content, file_path)
            if imports_chunk:
                chunks.append(imports_chunk)
            
            # 5. –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –º–æ–¥—É–ª—è
            module_doc_chunk = await self._create_module_doc_chunk(tree, content, file_path)
            if module_doc_chunk:
                chunks.append(module_doc_chunk)
            
            logger.info(f"  üìÑ {Path(file_path).name}: {len(chunks)} —á–∞–Ω–∫–æ–≤")
            return chunks
            
        except Exception as e:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ {file_path}: {e}")
            return []
    
    async def _create_full_file_chunk(self, content: str, file_path: str) -> Optional[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–∞ —Å –ø–æ–ª–Ω—ã–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º —Ñ–∞–π–ª–∞"""
        if len(content) < 1000:  # –¢–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
            return {
                "content": f"–ü–æ–ª–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ {Path(file_path).name}:\n\n{content}",
                "file": file_path,
                "lines": f"1-{content.count(chr(10)) + 1}",
                "start_line": 1,
                "end_line": content.count(chr(10)) + 1,
                "type": "full_file",
                "chunk_id": hash(f"{file_path}_full")
            }
        return None
    
    async def _create_enhanced_class_chunk(self, node: ast.ClassDef, content: str, file_path: str) -> Optional[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ —á–∞–Ω–∫–∞ –∫–ª–∞—Å—Å–∞ —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        try:
            lines = content.split('\n')
            start_line = node.lineno
            end_line = node.end_lineno or start_line
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–¥ –∫–ª–∞—Å—Å–∞
            class_code = '\n'.join(lines[start_line-1:end_line])
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º docstring
            docstring = ast.get_docstring(node)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –º–µ—Ç–æ–¥—ã —Å –∏—Ö —Å–∏–≥–Ω–∞—Ç—É—Ä–∞–º–∏
            methods = []
            for child in node.body:
                if isinstance(child, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    method_info = {
                        'name': child.name,
                        'line': child.lineno,
                        'is_async': isinstance(child, ast.AsyncFunctionDef),
                        'params': [arg.arg for arg in child.args.args if arg.arg != 'self'],
                        'decorators': [d.id if isinstance(d, ast.Name) else str(d) for d in child.decorator_list]
                    }
                    methods.append(method_info)
            
            # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            methods_text = ""
            for method in methods:
                async_text = "async " if method['is_async'] else ""
                decorators_text = f"@{', @'.join(method['decorators'])} " if method['decorators'] else ""
                params_text = f"({', '.join(method['params'])})" if method['params'] else "()"
                methods_text += f"  - {decorators_text}{async_text}{method['name']}{params_text} (—Å—Ç—Ä–æ–∫–∞ {method['line']})\n"
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            chunk_content = f"""–ö–ª–∞—Å—Å {node.name} (—Å—Ç—Ä–æ–∫–∏ {start_line}-{end_line}):

–û–ø–∏—Å–∞–Ω–∏–µ: {docstring or '–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è'}

–ú–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Å–∞:
{methods_text}

–ü–æ–ª–Ω—ã–π –∫–æ–¥ –∫–ª–∞—Å—Å–∞:
```python
{class_code}
```"""
            
            return {
                "content": chunk_content,
                "file": file_path,
                "lines": f"{start_line}-{end_line}",
                "start_line": start_line,
                "end_line": end_line,
                "type": "class",
                "class_name": node.name,
                "methods_count": len(methods),
                "chunk_id": hash(f"{file_path}_{node.name}")
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —á–∞–Ω–∫–∞ –∫–ª–∞—Å—Å–∞ {node.name}: {e}")
            return None
    
    async def _create_enhanced_function_chunk(self, node: ast.FunctionDef, content: str, file_path: str) -> Optional[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ —á–∞–Ω–∫–∞ —Ñ—É–Ω–∫—Ü–∏–∏ —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        try:
            lines = content.split('\n')
            start_line = node.lineno
            end_line = node.end_lineno or start_line
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–¥ —Ñ—É–Ω–∫—Ü–∏–∏
            function_code = '\n'.join(lines[start_line-1:end_line])
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º docstring
            docstring = ast.get_docstring(node)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å —Ç–∏–ø–∞–º–∏
            params = []
            param_types = {}
            for arg in node.args.args:
                param_name = arg.arg
                params.append(param_name)
                if arg.annotation:
                    if isinstance(arg.annotation, ast.Name):
                        param_types[param_name] = arg.annotation.id
                    elif isinstance(arg.annotation, ast.Constant):
                        param_types[param_name] = str(arg.annotation.value)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º return type
            return_type = "Any"
            if node.returns:
                if isinstance(node.returns, ast.Name):
                    return_type = node.returns.id
                elif isinstance(node.returns, ast.Constant):
                    return_type = str(node.returns.value)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã
            decorators = []
            for decorator in node.decorator_list:
                if isinstance(decorator, ast.Name):
                    decorators.append(decorator.id)
                elif isinstance(decorator, ast.Attribute):
                    decorators.append(decorator.attr)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—ã–∑—ã–≤–∞–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤–Ω—É—Ç—Ä–∏
            called_functions = []
            for child in ast.walk(node):
                if isinstance(child, ast.Call):
                    if isinstance(child.func, ast.Name):
                        called_functions.append(child.func.id)
                    elif isinstance(child.func, ast.Attribute):
                        called_functions.append(child.func.attr)
            called_functions = list(set(called_functions))[:15]  # –£–≤–µ–ª–∏—á–∏–ª –¥–æ 15
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
            params_text = ", ".join([f"{k}: {v}" for k, v in param_types.items()]) if param_types else ", ".join(params)
            decorators_text = f"@{', @'.join(decorators)} " if decorators else ""
            calls_text = f"–í—ã–∑—ã–≤–∞–µ—Ç: {', '.join(called_functions)}" if called_functions else "–ù–µ –≤—ã–∑—ã–≤–∞–µ—Ç –≤–Ω–µ—à–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏"
            
            chunk_content = f"""–§—É–Ω–∫—Ü–∏—è {node.name} (—Å—Ç—Ä–æ–∫–∏ {start_line}-{end_line}):

–û–ø–∏—Å–∞–Ω–∏–µ: {docstring or '–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è'}

–°–∏–≥–Ω–∞—Ç—É—Ä–∞: {decorators_text}def {node.name}({params_text}) -> {return_type}
{calls_text}

–ü–æ–ª–Ω—ã–π –∫–æ–¥ —Ñ—É–Ω–∫—Ü–∏–∏:
```python
{function_code}
```"""
            
            return {
                "content": chunk_content,
                "file": file_path,
                "lines": f"{start_line}-{end_line}",
                "start_line": start_line,
                "end_line": end_line,
                "type": "function",
                "function_name": node.name,
                "parameters": params,
                "param_types": param_types,
                "return_type": return_type,
                "decorators": decorators,
                "calls_functions": called_functions,
                "is_async": isinstance(node, ast.AsyncFunctionDef),
                "chunk_id": hash(f"{file_path}_{node.name}")
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —á–∞–Ω–∫–∞ —Ñ—É–Ω–∫—Ü–∏–∏ {node.name}: {e}")
            return None
    
    async def _create_imports_chunk(self, tree: ast.AST, content: str, file_path: str) -> Optional[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–∞ —Å –∏–º–ø–æ—Ä—Ç–∞–º–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏"""
        try:
            imports = []
            from_imports = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        imports.append(f"import {alias.name}")
                elif isinstance(node, ast.ImportFrom):
                    module = node.module or ""
                    for alias in node.names:
                        from_imports.append(f"from {module} import {alias.name}")
            
            if not imports and not from_imports:
                return None
            
            imports_text = "\n".join(imports) if imports else ""
            from_imports_text = "\n".join(from_imports) if from_imports else ""
            
            chunk_content = f"""–ò–º–ø–æ—Ä—Ç—ã –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–æ–¥—É–ª—è {Path(file_path).name}:

–ü—Ä—è–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã:
{imports_text}

–ò–º–ø–æ—Ä—Ç—ã –∏–∑ –º–æ–¥—É–ª–µ–π:
{from_imports_text}

–í—Å–µ–≥–æ –∏–º–ø–æ—Ä—Ç–æ–≤: {len(imports) + len(from_imports)}"""
            
            return {
                "content": chunk_content,
                "file": file_path,
                "lines": "1-20",
                "start_line": 1,
                "end_line": 20,
                "type": "imports",
                "imports_count": len(imports),
                "from_imports_count": len(from_imports),
                "chunk_id": hash(f"{file_path}_imports")
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —á–∞–Ω–∫–∞ –∏–º–ø–æ—Ä—Ç–æ–≤: {e}")
            return None
    
    async def _create_module_doc_chunk(self, tree: ast.AST, content: str, file_path: str) -> Optional[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–∞ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π –º–æ–¥—É–ª—è"""
        try:
            module_docstring = ast.get_docstring(tree)
            if not module_docstring or len(module_docstring) < 50:
                return None
            
            chunk_content = f"""–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –º–æ–¥—É–ª—è {Path(file_path).name}:

{module_docstring}

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —è–≤–ª—è–µ—Ç—Å—è —á–∞—Å—Ç—å—é –ø—Ä–æ–µ–∫—Ç–∞ StaffProBot."""
            
            return {
                "content": chunk_content,
                "file": file_path,
                "lines": "1-10",
                "start_line": 1,
                "end_line": 10,
                "type": "module_docstring",
                "chunk_id": hash(f"{file_path}_module_docstring")
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —á–∞–Ω–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {e}")
            return None

async def main():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞"""
    indexer = EnhancedPythonIndexer()
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ
    test_file = "/projects/staffprobot/domain/entities/user.py"
    chunks = await indexer.index_file(test_file)
    
    logger.info(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ {test_file}:")
    logger.info(f"–°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")
    
    for i, chunk in enumerate(chunks, 1):
        logger.info(f"\n--- –ß–∞–Ω–∫ {i} ---")
        logger.info(f"–¢–∏–ø: {chunk['type']}")
        logger.info(f"–°—Ç—Ä–æ–∫–∏: {chunk['lines']}")
        logger.info(f"–†–∞–∑–º–µ—Ä: {len(chunk['content'])} —Å–∏–º–≤–æ–ª–æ–≤")
        logger.info(f"–ü—Ä–µ–≤—å—é: {chunk['content'][:200]}...")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
